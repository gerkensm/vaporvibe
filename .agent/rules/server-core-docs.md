---
trigger: always_on
globs: **/*
---


# Content from docs/modules/server/server.md

# Module Documentation: `server/server.ts`

> **File**: `src/server/server.ts`  
> **Last Updated**: Sat Nov 22 14:30:28 2025 +0100  
> **Commit ID**: `8436e2adacde383517a4ecbe08e576b9076a7f74`

> [!WARNING]
> This documentation is manually maintained and may be outdated. Always verify against the source code.

## Overview
`server.ts` is the core entry point and orchestrator of the VaporVibe backend. It is responsible for:
1.  **HTTP Server Lifecycle**: Creating and managing the Node.js `http.Server`.
2.  **State Management**: Holding the global mutable state (`MutableServerState`) that persists across requests.
3.  **Routing**: Dispatching requests to appropriate handlers (Admin API, REST API, Frontend Assets, LLM Streams).
4.  **Frontend Integration**: Serving the Single Page Application (SPA) shell and its assets, including handling dev-server proxying.
5.  **LLM Orchestration**: Managing the lifecycle of LLM streams, including the unique "Reasoning Stream" mechanism for side-channel thought injection.

## Core Concepts & Implementation Details

### 1. Mutable Server State (`MutableServerState`)
The server avoids a complex dependency injection container in favor of a single, mutable state object passed by reference.

> [!WARNING]
> **Volatility**: This state object is a singleton that lives in memory. It is **not** persisted to disk. If the server restarts, all `pendingHtml` and `reasoningStreams` are lost immediately. This is why the "Loading Shell" must handle 404s gracefully.

-   **Definition**: See `interface MutableServerState`.
-   **Lifecycle**: Created in `createServerState()` at startup.
-   **Key Fields**:
    -   `runtime`: Static config resolved at startup.
    -   `provider`: Dynamic settings (API keys, models) that can change at runtime.
    -   `llmClient`: The active, instantiated LLM client. Re-created when provider settings change.
    -   `reasoningStreams`: A map of active "thought" streams (see below).
    -   `pendingHtml`: A temporary cache for HTML content generated by the LLM but waiting to be fetched by the frontend loader.

### 2. The "Reasoning Stream" Mechanism
To support "thinking" models (like Gemini or DeepSeek) or to inject custom reasoning traces into the UI without breaking the standard text stream, the server implements a side-channel SSE stream.
-   **Registration**: `registerReasoningStream(state)` creates a unique token and an in-memory event buffer.
-   **Injection**: The server injects a script tag into the HTML response: `window.__VAPORVIBE_REASONING_STREAM_TOKEN = "..."`.
-   **Consumption**: The frontend connects to `/__vaporvibe/reasoning-stream/:token`.
-   **Buffering**: Events are buffered (`REASONING_STREAM_EVENT_LIMIT = 200`) so that if the frontend connects late, it receives prior events.
-   **Cleanup**: `cleanupReasoningStreams` runs periodically to remove expired streams (TTL 10 mins).

### 3. Frontend Asset Serving & Dev Proxy
The server needs to serve the React frontend, which can be in two states:
-   **Production**: Static files in `frontend/dist`. The server uses `maybeServeFrontendAsset` to serve these with proper caching headers (`ETag`, `Last-Modified`). It handles the "SPA Fallback" (serving `index.html` for unknown routes) in `serveSpaShell`.
-   **Development**: If `VAPORVIBE_PREFER_DEV_FRONTEND` is set or if a `DevFrontendServer` (Vite) is passed, it proxies requests to the Vite dev server. This allows for HMR (Hot Module Replacement) while developing.

### 4. Component Caching & Reusability
To optimize performance and token usage, the server implements a "Component Cache" mechanism.
-   **Logic**: `buildMasterReusableCaches` scans the chat history to find rendered HTML components that can be reused.
-   **Application**: `applyReusablePlaceholders` replaces these known components in the prompt with placeholders, reducing the context window size sent to the LLM.

## Key Functions

### `createVaporVibeServer(config: RuntimeConfig, ...)`
The main factory.
-   **Inputs**: Configuration and optional dev server instance.
-   **Outputs**: An `http.Server` instance.
-   **Logic**:
    1.  Initializes `SessionStore`.
    2.  Creates `MutableServerState`.
    3.  Sets up the `requestListener` which acts as the central router.
    4.  Handles `upgrade` events for WebSocket support (needed for Vite HMR).

### `requestListener(req, res)`
The central router. It creates a `RequestContext` and dispatches based on URL:
1.  **CORS**: Handles preflight `OPTIONS` requests.
2.  **Reasoning Streams**: Routes `/__vaporvibe/reasoning-stream/*` to `serveReasoningStream`.
3.  **Admin API**: Routes `/admin/*` to `AdminController.handle`.
4.  **REST API**: Routes `/rest_api/*` to `RestApiController.handle`.
5.  **Assets**: Checks `maybeServeFrontendAsset`.
6.  **LLM Completion**: Routes `POST /` (or specific configured paths) to `handleLlmRequest`.
7.  **Fallback**: Serves the SPA shell (`serveSpaShell`) for all other GET requests.

### `handleLlmRequest(context, state)`
Orchestrates the chat completion flow.
1.  **Validation**: Checks if a provider is configured and ready.
2.  **History Selection**: Calls `selectHistoryForPrompt` to prepare the context.
3.  **Client Creation**: Uses `createLlmClient` (if not already cached).
4.  **Stream Setup**: Creates a `LlmStreamObserver` to capture reasoning events.
5.  **Execution**: Calls `client.streamChat`.
6.  **Response Streaming**: Pipes the text chunks to the HTTP response.
7.  **Error Handling**: Catches LLM errors and sends appropriate HTTP status codes (e.g., 503 for overloaded, 401 for bad keys).

## Data Formats

### Internal: `PendingHtmlEntry`
Used to temporarily store HTML generated by the LLM so the frontend can fetch it via a separate request (avoiding large payloads in the main stream).
```typescript
{
  html: string;
  expiresAt: number; // Timestamp
}
```

### Internal: `ReasoningStreamEntry`
State for an active reasoning side-channel.
```typescript
{
  createdAt: number;
  events: string[]; // Buffered SSE events
  closed: boolean;
  subscriber?: ServerResponse | null; // The active HTTP connection
}
```

## Shortcomings & Technical Debt

### Architectural
-   **Routing Monolith**: The `requestListener` function is a massive `if/else` block. It manually handles URL parsing, method checking, and dispatching. This is fragile and hard to read. **Recommendation**: Refactor into a `Router` class or use a micro-framework like `h3`.
-   **Global State Mutation**: The `state` object is mutated in place by various controllers. This makes it hard to track *who* changed a setting and *when*. **Recommendation**: Use a Redux-like pattern or a dedicated `StateManager` class with explicit setter methods that emit events.

### Implementation
-   **Asset Serving**: The manual implementation of static file serving (`maybeServeFrontendAsset`) re-invents the wheel (mime types, caching headers, range requests). **Recommendation**: Use `serve-handler` or `sirv`.
-   **Error Boundaries**: While there are `try/catch` blocks, unhandled promise rejections in the async request handler could potentially crash the process. **Recommendation**: Wrap the top-level handler in a safe execution context.

